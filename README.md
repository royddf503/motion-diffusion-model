# MDM Motion Generation: Advancing the Perception of Time in Motion

This repository contains the code and documentation for our project focused on advancing the perception of time in motion generation using the Motion Diffusion Model (MDM). Led by Roy Diamant, Ben Barak, and Bar Shaked, our team has developed novel techniques to address the challenges associated with accurately perceiving and representing temporal relationships within natural language text when generating human motion sequences.

The comprehensive details of our work are provided in the attached document titled "MDM - Final Report."
The comprehensive details of our work are provided in the attached document titled 'MDM - Final Report'. Additionally, for ongoing developments in this area, you can refer to https://github.com/GuyTevet/motion-diffusion-model.
## Key Features

1. **Temporal Text Analyzer:** Our custom Python script employs regular expressions to split input sentences based on temporal conjunctions, providing a precise understanding of temporal relationships.
2. **In-Betweening Enhancement:** We extended the MDM's in-betweening feature to support custom motions and enable seamless transitions between multiple motions.
3. **Motion Gap Function (MGF):** Our MGF predicts the optimal number of frames between motion segments for smooth and realistic transitions, incorporating techniques from "Generating Diverse and Natural 3D Human Motion from Text."

![image](https://github.com/royddf503/motion-diffusion-model/assets/43114148/cf883e98-912b-48eb-a667-d5ade5bbda36)

## The Problem
![image](https://github.com/royddf503/motion-diffusion-model/assets/43114148/164c0cef-f063-46b3-b350-40ef429fff8b)
Example of a motion generated by the MDM model based on the input text 'The person jumps and then raises his hands.' In this sequence, the model generates a motion of the person jumping and raising his hands simultaneously instead of jumping and then raising his hands. This highlights the challenge of perceiving temporal relationships in natural language and the need for improved models to address this issue
## Suggested Solution Model
![image](https://github.com/royddf503/motion-diffusion-model/assets/43114148/6da7986c-02af-4f06-aa97-94ed5993c09d)
Flowchart illustrating motion generation for the sentence 'The person dances and then claps his hands' using the proposed solution. The sentence is broken down into smaller sentences based on temporal relationships: 'The person dances' and 'The person claps his hands'. The Motion Diffusion Model (MDM) generates unique motions for each segment, i.e., dancing and clapping. The motions are then combined using in-betweening to create coherent motion, while ensuring they are arranged in the correct order of temporal events.

## Results

Our solution effectively overcomes the limitations of the original MDM model, accurately capturing temporal relationships within input text and generating coherent and natural motion sequences. We have extensively tested and evaluated our methods, demonstrating significant improvements in motion generation quality.

## Future Directions

Looking ahead, we aim to further enhance our techniques by exploring advanced machine learning models and improving the quality and diversity of annotated training data. These efforts will enable us to better handle complex temporal relationships and provide more accurate and informative motion generation from text inputs.

## Contributions

We invite contributions from the community to help advance the field of motion generation and temporal perception. Whether through code improvements, additional features, or dataset enhancements, your contributions are valuable in pushing the boundaries of what is possible in generating human-like motion from natural language descriptions.
